# =====================================================
# ICT Trading Bot - Otomatik Optimizasyon ModÃ¼lÃ¼
# =====================================================
# Kazanma/kaybetme havuzunu analiz ederek parametreleri
# otomatik gÃ¼nceller ve sÃ¼rekli Ã¶ÄŸrenir.
# =====================================================

import logging
import json
from datetime import datetime
from database import (
    get_completed_signals, get_performance_summary,
    get_component_performance, save_bot_param, get_bot_param,
    add_optimization_log, get_all_bot_params, get_loss_analysis
)
from config import ICT_PARAMS, OPTIMIZER_CONFIG

logger = logging.getLogger("ICT-Bot.Optimizer")


class SelfOptimizer:
    """
    Otomatik Ã¶ÄŸrenen optimizer.
    Her optimizasyon dÃ¶ngÃ¼sÃ¼nde:
    1. Tamamlanan iÅŸlemleri analiz et
    2. BileÅŸen bazlÄ± performansÄ± deÄŸerlendir
    3. ZayÄ±f parametreleri tespit et
    4. KontrollÃ¼ ÅŸekilde gÃ¼ncelle
    5. Log tut
    """

    def __init__(self):
        self.learning_rate = OPTIMIZER_CONFIG["learning_rate"]
        self.max_change = OPTIMIZER_CONFIG["max_param_change_pct"]
        self.min_trades = OPTIMIZER_CONFIG["min_trades_for_optimization"]
        self.target_win_rate = OPTIMIZER_CONFIG["win_rate_target"]
        self.optimization_history = []

    def run_optimization(self):
        """Ana optimizasyon dÃ¶ngÃ¼sÃ¼"""
        logger.info("ğŸ”„ Optimizasyon dÃ¶ngÃ¼sÃ¼ baÅŸlatÄ±lÄ±yor...")

        stats = get_performance_summary()
        total_trades = stats["total_trades"]

        if total_trades < self.min_trades:
            logger.info(f"Yeterli iÅŸlem yok ({total_trades}/{self.min_trades}), optimizasyon atlanÄ±yor.")
            return {
                "status": "SKIPPED",
                "reason": f"Minimum {self.min_trades} iÅŸlem gerekli, ÅŸu an: {total_trades}",
                "changes": []
            }

        changes = []

        # 1. Win Rate bazlÄ± gÃ¼ven eÅŸiÄŸi ayarlama
        wr_change = self._optimize_confidence_threshold(stats)
        if wr_change:
            changes.append(wr_change)

        # 2. BileÅŸen bazlÄ± aÄŸÄ±rlÄ±k ayarlama
        comp_changes = self._optimize_component_weights(stats)
        changes.extend(comp_changes)

        # 3. Risk yÃ¶netimi parametreleri
        risk_changes = self._optimize_risk_params(stats)
        changes.extend(risk_changes)

        # 4. SabÄ±rlÄ± mod ayarlarÄ±
        patience_change = self._optimize_patience(stats)
        if patience_change:
            changes.append(patience_change)

        # 5. KayÄ±p analizi â†’ derin Ã¶ÄŸrenme (neden kaybettik?)
        loss_changes = self._learn_from_losses()
        changes.extend(loss_changes)

        if changes:
            logger.info(f"âœ… Optimizasyon tamamlandÄ±: {len(changes)} parametre gÃ¼ncellendi")
        else:
            logger.info("â„¹ï¸ Optimizasyon: DeÄŸiÅŸiklik gerekli deÄŸil")

        return {
            "status": "COMPLETED",
            "total_trades_analyzed": total_trades,
            "win_rate": stats["win_rate"],
            "changes": changes
        }

    def _optimize_confidence_threshold(self, stats):
        """
        Win rate'e gÃ¶re minimum gÃ¼ven eÅŸiÄŸini ayarla:
        - Win rate dÃ¼ÅŸÃ¼kse -> eÅŸiÄŸi yÃ¼kselt (daha seÃ§ici ol)
        - Win rate hedefin Ã¼stÃ¼ndeyse -> eÅŸiÄŸi biraz dÃ¼ÅŸÃ¼r (daha fazla fÄ±rsat)
        """
        current_wr = stats["win_rate"] / 100
        current_threshold = get_bot_param("min_confidence", ICT_PARAMS["min_confidence"])

        if current_wr < self.target_win_rate * 0.85:
            # Win rate Ã§ok dÃ¼ÅŸÃ¼k, eÅŸiÄŸi yÃ¼kselt
            adjustment = self.learning_rate * (self.target_win_rate - current_wr) * 100
            new_threshold = min(90, current_threshold + adjustment)
            reason = f"Win rate dÃ¼ÅŸÃ¼k ({stats['win_rate']}%), gÃ¼ven eÅŸiÄŸi yÃ¼kseltiliyor"

        elif current_wr > self.target_win_rate * 1.15:
            # Win rate Ã§ok yÃ¼ksek, biraz daha fazla sinyal Ã¼retilebilir
            adjustment = self.learning_rate * 5
            new_threshold = max(55, current_threshold - adjustment)
            reason = f"Win rate yÃ¼ksek ({stats['win_rate']}%), gÃ¼ven eÅŸiÄŸi dÃ¼ÅŸÃ¼rÃ¼lÃ¼yor"

        else:
            return None

        new_threshold = round(new_threshold, 1)
        if abs(new_threshold - current_threshold) < 0.5:
            return None

        # Uygula ve logla
        save_bot_param("min_confidence", new_threshold, ICT_PARAMS["min_confidence"])
        add_optimization_log(
            "min_confidence", current_threshold, new_threshold, reason,
            stats["win_rate"], stats["win_rate"], stats["total_trades"]
        )

        logger.info(f"ğŸ“Š GÃ¼ven eÅŸiÄŸi: {current_threshold} -> {new_threshold} ({reason})")

        return {
            "param": "min_confidence",
            "old": current_threshold,
            "new": new_threshold,
            "reason": reason
        }

    def _optimize_component_weights(self, stats):
        """
        BileÅŸen bazlÄ± performans analizi:
        - BaÅŸarÄ±lÄ± bileÅŸenlerin aÄŸÄ±rlÄ±ÄŸÄ±nÄ± artÄ±r (dolaylÄ± olarak)
        - BaÅŸarÄ±sÄ±z bileÅŸenlerin etkisini azalt
        """
        changes = []
        comp_perf = stats.get("component_performance", {})

        if not comp_perf:
            return changes

        # Her bileÅŸen iÃ§in confluence score eÅŸiklerini ayarla
        param_mapping = {
            "ORDER_BLOCK": "ob_body_ratio_min",
            "FVG": "fvg_min_size_pct",
            "LIQUIDITY_SWEEP": "liquidity_equal_tolerance",
            "DISPLACEMENT": "displacement_min_body_ratio"
        }

        for comp_name, param_name in param_mapping.items():
            if comp_name not in comp_perf:
                continue

            comp = comp_perf[comp_name]
            if comp["total"] < 5:  # Yeterli veri yok
                continue

            win_rate = comp["win_rate"] / 100
            current_val = get_bot_param(param_name, ICT_PARAMS[param_name])
            new_val = current_val

            if win_rate < 0.4:
                # Bu bileÅŸen kÃ¶tÃ¼ performans gÃ¶steriyor - daha seÃ§ici ol
                adjustment = current_val * self.learning_rate
                new_val = current_val + adjustment
                reason = f"{comp_name} dÃ¼ÅŸÃ¼k WR ({comp['win_rate']}%), daha seÃ§ici"

            elif win_rate > 0.75:
                # Ã‡ok iyi performans - biraz gevÅŸet
                adjustment = current_val * self.learning_rate * 0.5
                new_val = max(current_val * 0.5, current_val - adjustment)
                reason = f"{comp_name} yÃ¼ksek WR ({comp['win_rate']}%), biraz gevÅŸetiliyor"

            else:
                continue

            # Max deÄŸiÅŸim sÄ±nÄ±rÄ±
            max_change_abs = current_val * self.max_change
            if abs(new_val - current_val) > max_change_abs:
                new_val = current_val + (max_change_abs if new_val > current_val else -max_change_abs)

            new_val = round(new_val, 6)
            if abs(new_val - current_val) < current_val * 0.01:
                continue

            save_bot_param(param_name, new_val, ICT_PARAMS[param_name])
            add_optimization_log(
                param_name, current_val, new_val, reason,
                stats["win_rate"], stats["win_rate"], stats["total_trades"]
            )

            changes.append({
                "param": param_name,
                "old": current_val,
                "new": new_val,
                "reason": reason
            })

            logger.info(f"ğŸ“Š {param_name}: {current_val} -> {new_val} ({reason})")

        return changes

    def _optimize_risk_params(self, stats):
        """
        Risk yÃ¶netimi parametrelerini optimize et:
        - Ortalama RR oranÄ±na gÃ¶re TP/SL ayarla
        - Kaybeden iÅŸlemlerdeki SL mesafesini analiz et
        """
        changes = []

        completed = get_completed_signals(50)
        if len(completed) < self.min_trades:
            return changes

        # Kazanan/kaybeden analizi
        winners = [s for s in completed if s["status"] == "WON"]
        losers = [s for s in completed if s["status"] == "LOST"]

        if not losers:
            return changes

        # Ortalama kayÄ±p yÃ¼zdesi
        avg_loss = sum(abs(s["pnl_pct"]) for s in losers) / len(losers) if losers else 0
        avg_win = sum(abs(s["pnl_pct"]) for s in winners) / len(winners) if winners else 0

        current_sl = get_bot_param("default_sl_pct", ICT_PARAMS["default_sl_pct"])
        current_tp_ratio = get_bot_param("default_tp_ratio", ICT_PARAMS["default_tp_ratio"])

        # SL Ã§ok sÄ±k tetikleniyorsa (kayÄ±p oranÄ± yÃ¼ksek) ve ortalama kayÄ±p artÄ±yorsa
        loss_rate = len(losers) / len(completed) if completed else 0

        if loss_rate > 0.55 and avg_loss > current_sl * 100 * 0.9:
            # SL'yi biraz geniÅŸlet (market noise'Ä± azalt)
            new_sl = min(current_sl * 1.1, 0.03)  # Max %3
            new_sl = round(new_sl, 4)

            if abs(new_sl - current_sl) > 0.0005:
                save_bot_param("default_sl_pct", new_sl, ICT_PARAMS["default_sl_pct"])
                reason = f"KayÄ±p oranÄ± yÃ¼ksek ({loss_rate:.0%}), SL geniÅŸletiliyor"
                add_optimization_log(
                    "default_sl_pct", current_sl, new_sl, reason,
                    stats["win_rate"], stats["win_rate"], stats["total_trades"]
                )
                changes.append({
                    "param": "default_sl_pct",
                    "old": current_sl,
                    "new": new_sl,
                    "reason": reason
                })

        # RR oranÄ± ayarlama
        if avg_win > 0 and avg_loss > 0:
            actual_rr = avg_win / avg_loss
            if actual_rr < 1.5 and current_tp_ratio < 3.5:
                new_tp_ratio = min(current_tp_ratio + 0.2, 4.0)
                new_tp_ratio = round(new_tp_ratio, 1)

                save_bot_param("default_tp_ratio", new_tp_ratio, ICT_PARAMS["default_tp_ratio"])
                reason = f"GerÃ§ek RR dÃ¼ÅŸÃ¼k ({actual_rr:.1f}), TP oranÄ± artÄ±rÄ±lÄ±yor"
                add_optimization_log(
                    "default_tp_ratio", current_tp_ratio, new_tp_ratio, reason,
                    stats["win_rate"], stats["win_rate"], stats["total_trades"]
                )
                changes.append({
                    "param": "default_tp_ratio",
                    "old": current_tp_ratio,
                    "new": new_tp_ratio,
                    "reason": reason
                })

        return changes

    def _optimize_patience(self, stats):
        """
        SabÄ±rlÄ± mod optimizasyonu:
        - Watch'tan promote edilen sinyallerin baÅŸarÄ±sÄ±nÄ± analiz et
        - Bekleme sÃ¼resini ayarla
        """
        current_watch = get_bot_param("patience_watch_candles", ICT_PARAMS["patience_watch_candles"])
        completed = get_completed_signals(50)

        if len(completed) < self.min_trades:
            return None

        # DÃ¼ÅŸÃ¼k gÃ¼venle aÃ§Ä±lan iÅŸlemlerin sonuÃ§larÄ±nÄ± analiz et
        low_conf_trades = [s for s in completed if s["confidence"] and s["confidence"] < 70]
        high_conf_trades = [s for s in completed if s["confidence"] and s["confidence"] >= 70]

        if not low_conf_trades or not high_conf_trades:
            return None

        low_wr = sum(1 for s in low_conf_trades if s["status"] == "WON") / len(low_conf_trades)
        high_wr = sum(1 for s in high_conf_trades if s["status"] == "WON") / len(high_conf_trades)

        # DÃ¼ÅŸÃ¼k gÃ¼venli iÅŸlemler Ã§ok baÅŸarÄ±sÄ±zsa, daha sabÄ±rlÄ± ol
        if low_wr < 0.35 and current_watch < 5:
            new_watch = min(current_watch + 1, 5)
            reason = f"DÃ¼ÅŸÃ¼k gÃ¼venli WR: {low_wr:.0%}, bekleme artÄ±rÄ±lÄ±yor"

            save_bot_param("patience_watch_candles", new_watch, ICT_PARAMS["patience_watch_candles"])
            add_optimization_log(
                "patience_watch_candles", current_watch, new_watch, reason,
                stats["win_rate"], stats["win_rate"], stats["total_trades"]
            )

            return {
                "param": "patience_watch_candles",
                "old": current_watch,
                "new": new_watch,
                "reason": reason
            }

        return None

    def get_optimization_summary(self):
        """Optimizasyon Ã¶zetini dÃ¶ndÃ¼r"""
        stats = get_performance_summary()
        all_params = get_all_bot_params()
        loss_info = get_loss_analysis(30)

        # VarsayÄ±landan deÄŸiÅŸen parametreleri bul
        changed_params = {}
        for key, default_val in ICT_PARAMS.items():
            current_val = all_params.get(key, default_val)
            if isinstance(current_val, (int, float)) and isinstance(default_val, (int, float)):
                if abs(current_val - default_val) > 0.0001:
                    changed_params[key] = {
                        "default": default_val,
                        "current": current_val,
                        "change_pct": round(((current_val - default_val) / default_val) * 100, 1)
                                      if default_val != 0 else 0
                    }

        return {
            "total_optimizations": len(changed_params),
            "current_win_rate": stats["win_rate"],
            "target_win_rate": self.target_win_rate * 100,
            "changed_params": changed_params,
            "performance": stats,
            "loss_lessons": loss_info.get("lesson_summary", []),
            "last_check": datetime.now().isoformat()
        }


    def _learn_from_losses(self):
        """
        KayÄ±p analizi yaparak otomatik ders Ã§Ä±kar.
        Neden kaybettik? Hangi bileÅŸen eksikti? Hangi bileÅŸen yanÄ±lttÄ±?
        """
        changes = []
        loss_info = get_loss_analysis(30)

        if loss_info["total_losses"] < 5:
            return changes

        stats = get_performance_summary()

        # 1. DÃ¼ÅŸÃ¼k gÃ¼venle girilen kayÄ±plar Ã§oÄŸunluksa â†’ min_confidence artÄ±r
        if loss_info["total_losses"] > 0:
            low_conf_ratio = loss_info["low_confidence_losses"] / loss_info["total_losses"]
            if low_conf_ratio > 0.4:
                current = get_bot_param("min_confidence", ICT_PARAMS["min_confidence"])
                # KÃ¼Ã§Ã¼k adÄ±mlarla artÄ±r (agresif deÄŸil, ideal)
                new_val = min(85, current + self.learning_rate * 15)
                new_val = round(new_val, 1)
                if new_val - current >= 1.0:
                    save_bot_param("min_confidence", new_val, ICT_PARAMS["min_confidence"])
                    reason = (f"KayÄ±plarÄ±n %{low_conf_ratio*100:.0f}'i dÃ¼ÅŸÃ¼k gÃ¼venli â€” "
                             f"eÅŸik {current} â†’ {new_val}")
                    add_optimization_log("min_confidence", current, new_val, reason,
                                        stats["win_rate"], stats["win_rate"], stats["total_trades"])
                    changes.append({"param": "min_confidence", "old": current,
                                   "new": new_val, "reason": reason})
                    logger.info(f"ğŸ§  DERS: {reason}")

        # 2. En Ã§ok eksik olan bileÅŸeni kontrol et â†’ confluence eÅŸiÄŸini ayarla
        missing = loss_info.get("missing_components", {})
        total_losses = loss_info["total_losses"]

        # Displacement kayÄ±plarda Ã§ok eksikse â†’ displacement cezasÄ±nÄ± artÄ±r
        disp_missing = missing.get("DISPLACEMENT", 0)
        if total_losses > 0 and disp_missing / total_losses > 0.6:
            current = get_bot_param("displacement_min_body_ratio",
                                   ICT_PARAMS["displacement_min_body_ratio"])
            # Displacement parametresini sÄ±kÄ±laÅŸtÄ±rmak yerine, confluence eÅŸiÄŸini hafif artÄ±r
            current_conf = get_bot_param("min_confluence_score", ICT_PARAMS["min_confluence_score"])
            new_conf = min(80, current_conf + 1.0)
            if new_conf > current_conf:
                save_bot_param("min_confluence_score", new_conf, ICT_PARAMS["min_confluence_score"])
                reason = (f"KayÄ±plarÄ±n %{disp_missing/total_losses*100:.0f}'inde DISPLACEMENT eksik â€” "
                         f"confluence {current_conf} â†’ {new_conf}")
                add_optimization_log("min_confluence_score", current_conf, new_conf, reason,
                                    stats["win_rate"], stats["win_rate"], stats["total_trades"])
                changes.append({"param": "min_confluence_score", "old": current_conf,
                               "new": new_conf, "reason": reason})
                logger.info(f"ğŸ§  DERS: {reason}")

        # 3. HTF onaysÄ±z kayÄ±plar Ã§oksa â†’ HTF uyumsuzluk cezasÄ±nÄ± artÄ±r (dolaylÄ±: eÅŸik)
        htf_missing = missing.get("HTF_CONFIRMATION", 0)
        if total_losses > 0 and htf_missing / total_losses > 0.65:
            reason = (f"KayÄ±plarÄ±n %{htf_missing/total_losses*100:.0f}'inde HTF onayÄ± yoktu â€” "
                     f"HTF uyumu kritik")
            logger.info(f"ğŸ§  NOT: {reason}")
            # Bu bilgiyi lesson olarak sakla, agresif parametre deÄŸiÅŸikliÄŸi yapma

        # 4. Ortalama kayÄ±p bÃ¼yÃ¼kse â†’ SL mesafesini kontrol et
        if loss_info["avg_loss_pct"] > 2.0:
            current_sl = get_bot_param("default_sl_pct", ICT_PARAMS["default_sl_pct"])
            # SL Ã§ok geniÅŸ olabilir, daralt
            new_sl = max(0.008, current_sl * 0.92)
            new_sl = round(new_sl, 4)
            if abs(new_sl - current_sl) > 0.001:
                save_bot_param("default_sl_pct", new_sl, ICT_PARAMS["default_sl_pct"])
                reason = (f"Ortalama kayÄ±p %{loss_info['avg_loss_pct']:.1f} Ã§ok yÃ¼ksek â€” "
                         f"SL {current_sl} â†’ {new_sl}")
                add_optimization_log("default_sl_pct", current_sl, new_sl, reason,
                                    stats["win_rate"], stats["win_rate"], stats["total_trades"])
                changes.append({"param": "default_sl_pct", "old": current_sl,
                               "new": new_sl, "reason": reason})
                logger.info(f"ğŸ§  DERS: {reason}")

        # Ders Ã¶zetini logla
        for lesson in loss_info.get("lesson_summary", []):
            logger.info(f"ğŸ“ Optimizer Ders: {lesson}")

        return changes


# Global instance
self_optimizer = SelfOptimizer()
